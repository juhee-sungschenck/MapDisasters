{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41076, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "      <th>n_sentence</th>\n",
       "      <th>n_words</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-31 23:15:25+00:00</td>\n",
       "      <td>a customer service rep told me friday there is...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>25.525284</td>\n",
       "      <td>-80.606920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-31 22:39:25+00:00</td>\n",
       "      <td>tomorrow at pm after hour with sabor havana ci...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>27.686273</td>\n",
       "      <td>-80.934588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-31 22:31:09+00:00</td>\n",
       "      <td>hurricane laura wallop area with high mortgage...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>27.701712</td>\n",
       "      <td>-75.255859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-31 20:25:29+00:00</td>\n",
       "      <td>i never wish bad on anyone but think we need a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>29.114762</td>\n",
       "      <td>-84.339632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-31 19:51:39+00:00</td>\n",
       "      <td>wth is pricemart so full their a hurricane idk...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>28.506867</td>\n",
       "      <td>-89.678090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date  \\\n",
       "0  2020-08-31 23:15:25+00:00   \n",
       "1  2020-08-31 22:39:25+00:00   \n",
       "2  2020-08-31 22:31:09+00:00   \n",
       "3  2020-08-31 20:25:29+00:00   \n",
       "4  2020-08-31 19:51:39+00:00   \n",
       "\n",
       "                                          text_clean  label  n_sentence  \\\n",
       "0  a customer service rep told me friday there is...      0           2   \n",
       "1  tomorrow at pm after hour with sabor havana ci...      0           2   \n",
       "2  hurricane laura wallop area with high mortgage...      0           2   \n",
       "3  i never wish bad on anyone but think we need a...      0           1   \n",
       "4  wth is pricemart so full their a hurricane idk...      0           2   \n",
       "\n",
       "   n_words        lat       long  \n",
       "0       11  25.525284 -80.606920  \n",
       "1       19  27.686273 -80.934588  \n",
       "2       13  27.701712 -75.255859  \n",
       "3        9  29.114762 -84.339632  \n",
       "4        5  28.506867 -89.678090  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in csv\n",
    "\n",
    "df = pd.read_csv('../data/final_hurricane_labeled.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date          0\n",
       "text_clean    0\n",
       "label         0\n",
       "n_sentence    0\n",
       "n_words       0\n",
       "lat           0\n",
       "long          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.526658\n",
       "1    0.473342\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define baseline accuracy\n",
    "\n",
    "df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up X and y and train test split\n",
    "\n",
    "X = df['text_clean']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .33, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom stop words\n",
    "\n",
    "irrelevant_words = ['aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', \n",
    "                  'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn', 'co', 'pm', 'wa', 'edt', 'amp', 'ha', 'cdt', 'one', 'state', 'hurricane', 'laura','hurricanelaura',\n",
    "                   'trump', 'texas', 'louisiana', 'tx', 'houston']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "216\n"
     ]
    }
   ],
   "source": [
    "# create a custom stop words list\n",
    "\n",
    "print(len(stopwords.words('english')))\n",
    "\n",
    "stop_words = stopwords.words('english') + irrelevant_words\n",
    "\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CountVectorizer()\n",
    "#### Multinomial Naive Bayes and Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set 2 pipelines with: 1. Multinomial Bayes 2. Support Vector Machine\n",
    "\n",
    "pipeline_mb = Pipeline([\n",
    "                       ('cvec', CountVectorizer()),\n",
    "                       ('mb', MultinomialNB())\n",
    "                       ])\n",
    "\n",
    "pipeline_svc = Pipeline([\n",
    "                        ('cvec', CountVectorizer()),\n",
    "                        ('svc', SVC())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dictionary to store the best parameters\n",
    "\n",
    "model_mb_params = {}\n",
    "count_mb = 0\n",
    "\n",
    "model_svc_params = {}\n",
    "count_svc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up parameters\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [4000],\n",
    "    'cvec__min_df': [1, 2, 3],\n",
    "    'cvec__max_df': [.85, .90, .95],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)],\n",
    "    'cvec__stop_words': [stop_words, None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate GridSearchCV - NaiveBayes\n",
    "\n",
    "gs_mb = GridSearchCV(pipeline_mb, \n",
    "                     param_grid = pipe_params, \n",
    "                     cv = 3) \n",
    "\n",
    "# instantiate GridSearchCV - SVC\n",
    "\n",
    "gs_svc = GridSearchCV(pipeline_svc, \n",
    "                      param_grid = pipe_params, \n",
    "                      cv = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase counter as we put in different parameters\n",
    "\n",
    "count_mb += 1\n",
    "\n",
    "# fit the training set\n",
    "\n",
    "gs_mb.fit(X_train, y_train)\n",
    "\n",
    "# best score is not captured in parameters -> create a key 'score' to store the info\n",
    "\n",
    "gs_mb.best_params_['score'] = gs_mb.best_score_\n",
    "\n",
    "model_mb_params[f'model_{count_mb}'] = gs_mb.best_params_\n",
    "\n",
    "# dictionary to a dataframe\n",
    "\n",
    "model_mb_df = pd.DataFrame.from_dict(model_mb_params, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvec__max_df</th>\n",
       "      <th>cvec__max_features</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>cvec__ngram_range</th>\n",
       "      <th>cvec__stop_words</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>0.921293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cvec__max_df  cvec__max_features  cvec__min_df cvec__ngram_range  \\\n",
       "model_1          0.85                4000             1            (1, 1)   \n",
       "\n",
       "                                          cvec__stop_words     score  \n",
       "model_1  [i, me, my, myself, we, our, ours, ourselves, ...  0.921293  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase counter as we put in different parameters\n",
    "\n",
    "count_svc += 1\n",
    "\n",
    "# fit the training set\n",
    "\n",
    "gs_svc.fit(X_train, y_train)\n",
    "\n",
    "# best score is not captured in parameters -> create a key 'score' to store the info\n",
    "\n",
    "gs_svc.best_params_['score'] = gs_svc.best_score_\n",
    "\n",
    "model_svc_params[f'model_{count_svc}'] = gs_svc.best_params_\n",
    "\n",
    "# dictionary to a dataframe\n",
    "\n",
    "model_svc_df = pd.DataFrame.from_dict(model_svc_params, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvec__max_df</th>\n",
       "      <th>cvec__max_features</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>cvec__ngram_range</th>\n",
       "      <th>cvec__stop_words</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.98343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cvec__max_df  cvec__max_features  cvec__min_df cvec__ngram_range  \\\n",
       "model_1          0.85                4000             1            (1, 1)   \n",
       "\n",
       "        cvec__stop_words    score  \n",
       "model_1             None  0.98343  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes: 0.937609011627907\n",
      "\n",
      "SVC: 0.9987281976744186\n"
     ]
    }
   ],
   "source": [
    "# train set score\n",
    "\n",
    "print(f'Multinomial Naive Bayes: {gs_mb.score(X_train, y_train)}')\n",
    "print(f'\\nSVC: {gs_svc.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes: 0.9263794629684272\n",
      "\n",
      "SVC: 0.991664207730894\n"
     ]
    }
   ],
   "source": [
    "# test set score\n",
    "\n",
    "print(f'Multinomial Naive Bayes: {gs_mb.score(X_test, y_test)}')\n",
    "print(f'\\nSVC: {gs_svc.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes: \n",
      "{'cvec__max_df': 0.85, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn', 'co', 'pm', 'wa', 'edt', 'amp', 'ha', 'cdt', 'one', 'state', 'hurricane', 'laura', 'hurricanelaura', 'trump', 'texas', 'louisiana', 'tx', 'houston'], 'score': 0.9212934380798781}\n",
      "\n",
      "SVC: \n",
      "{'cvec__max_df': 0.85, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': None, 'score': 0.9834302325143839}\n"
     ]
    }
   ],
   "source": [
    "# find the best parameters for both models\n",
    "\n",
    "print(f'Multinomial Naive Bayes: \\n{gs_mb.best_params_}')\n",
    "print(f'\\nSVC: \\n{gs_svc.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes: \n",
      "Pipeline(steps=[('cvec',\n",
      "                 CountVectorizer(max_df=0.85, max_features=4000,\n",
      "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
      "                                             'our', 'ours', 'ourselves', 'you',\n",
      "                                             \"you're\", \"you've\", \"you'll\",\n",
      "                                             \"you'd\", 'your', 'yours',\n",
      "                                             'yourself', 'yourselves', 'he',\n",
      "                                             'him', 'his', 'himself', 'she',\n",
      "                                             \"she's\", 'her', 'hers', 'herself',\n",
      "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
      "                ('mb', MultinomialNB())])\n",
      "\n",
      "SVC: \n",
      "Pipeline(steps=[('cvec', CountVectorizer(max_df=0.85, max_features=4000)),\n",
      "                ('svc', SVC())])\n"
     ]
    }
   ],
   "source": [
    "# find the best estimators for both models\n",
    "\n",
    "print(f'Multinomial Naive Bayes: \\n{gs_mb.best_estimator_}')\n",
    "print(f'\\nSVC: \\n{gs_svc.best_estimator_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "\n",
    "y_preds = gs_svc.predict(X_test)\n",
    "\n",
    "# confusion matrix values\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view confusion matrix\n",
    "\n",
    "plot_confusion_matrix(gs_svc, X_test, y_test, cmap = 'Blues', normalize = 'true');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TfidfVectorizer()\n",
    "#### Multinomial Naive Bayes and Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up 2 pipelines with: 1. Multinomial Naive Bayes 2. SVC\n",
    "\n",
    "pipe_mb_t = Pipeline([\n",
    "                      ('tvec', TfidfVectorizer()),\n",
    "                      ('mb', MultinomialNB())\n",
    "                     ])\n",
    "\n",
    "pipe_svc_t = Pipeline([\n",
    "                       ('tvec', TfidfVectorizer()),\n",
    "                       ('svc', SVC())\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dictionary to store the best parameters\n",
    "\n",
    "t_mb_params = {}\n",
    "t_count_mb = 0\n",
    "\n",
    "t_svc_params = {}\n",
    "t_count_svc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search over the following values of hyperparameters:\n",
    "\n",
    "pipe_tvec_params = {\n",
    "    'tvec__max_features': [4000],\n",
    "    'tvec__stop_words': [stop_words, None],\n",
    "    'tvec__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tvec__min_df': [0.001, 0.002, 0.003],\n",
    "    'tvec__max_df': [0.85, 0.90, 0.95]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate GridSearchCV\n",
    "\n",
    "gs_mb_t = GridSearchCV(pipe_mb_t,\n",
    "                       param_grid = pipe_tvec_params,\n",
    "                       cv = 3)\n",
    "\n",
    "gs_svc_t = GridSearchCV(pipe_svc_t,\n",
    "                        param_grid = pipe_tvec_params,\n",
    "                        cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase counter as we put in different parameters\n",
    "\n",
    "t_count_mb += 1\n",
    "\n",
    "# fit the training set\n",
    "\n",
    "gs_mb_t.fit(X_train, y_train)\n",
    "\n",
    "# best score is not captured in parameters -> create a key 'score' to store the info\n",
    "\n",
    "gs_mb_t.best_params_['score'] = gs_mb_t.best_score_\n",
    "\n",
    "t_mb_params[f'model_{t_count_mb}'] = gs_mb_t.best_params_\n",
    "\n",
    "# dictionary to a dataframe\n",
    "\n",
    "t_mb_df = pd.DataFrame.from_dict(t_mb_params, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tvec__max_df</th>\n",
       "      <th>tvec__max_features</th>\n",
       "      <th>tvec__min_df</th>\n",
       "      <th>tvec__ngram_range</th>\n",
       "      <th>tvec__stop_words</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>4000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>0.898764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tvec__max_df  tvec__max_features  tvec__min_df tvec__ngram_range  \\\n",
       "model_1          0.85                4000         0.003            (1, 1)   \n",
       "\n",
       "                                          tvec__stop_words     score  \n",
       "model_1  [i, me, my, myself, we, our, ours, ourselves, ...  0.898764  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase counter as we put in different parameters\n",
    "\n",
    "t_count_svc += 1\n",
    "\n",
    "# fit the training set\n",
    "\n",
    "gs_svc_t.fit(X_train, y_train)\n",
    "\n",
    "# best score is not captured in parameters -> create a key 'score' to store the info\n",
    "\n",
    "gs_svc_t.best_params_['score'] = gs_svc_t.best_score_\n",
    "\n",
    "t_svc_params[f'model_{t_count_svc}'] = gs_svc_t.best_params_\n",
    "\n",
    "# dictionary to a dataframe\n",
    "\n",
    "t_svc_df = pd.DataFrame.from_dict(t_svc_params, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tvec__max_df</th>\n",
       "      <th>tvec__max_features</th>\n",
       "      <th>tvec__min_df</th>\n",
       "      <th>tvec__ngram_range</th>\n",
       "      <th>tvec__stop_words</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>4000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.990698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tvec__max_df  tvec__max_features  tvec__min_df tvec__ngram_range  \\\n",
       "model_1          0.85                4000         0.002            (1, 1)   \n",
       "\n",
       "        tvec__stop_words     score  \n",
       "model_1             None  0.990698  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_svc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes: 0.8987644369108739\n",
      "\n",
      "SVC: 0.990697708723005\n"
     ]
    }
   ],
   "source": [
    "# best scores\n",
    "\n",
    "print(f'Multinomial Naive Bayes: {gs_mb_t.best_score_}')\n",
    "print(f'\\nSVC: {gs_svc_t.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes: 0.9108284883720931\n",
      "\n",
      "SVC: 0.999781976744186\n"
     ]
    }
   ],
   "source": [
    "# train data accuracy score \n",
    "\n",
    "print(f'Multinomial Naive Bayes: {gs_mb_t.score(X_train, y_train)}')\n",
    "print(f'\\nSVC: {gs_svc_t.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes: 0.9069046916494541\n",
      "\n",
      "SVC: 0.9954263794629684\n"
     ]
    }
   ],
   "source": [
    "# test data accuracy score \n",
    "\n",
    "print(f'Multinomial Naive Bayes: {gs_mb_t.score(X_test, y_test)}')\n",
    "print(f'\\nSVC: {gs_svc_t.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes: \n",
      "Pipeline(steps=[('tvec',\n",
      "                 TfidfVectorizer(max_df=0.85, max_features=4000, min_df=0.003,\n",
      "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
      "                                             'our', 'ours', 'ourselves', 'you',\n",
      "                                             \"you're\", \"you've\", \"you'll\",\n",
      "                                             \"you'd\", 'your', 'yours',\n",
      "                                             'yourself', 'yourselves', 'he',\n",
      "                                             'him', 'his', 'himself', 'she',\n",
      "                                             \"she's\", 'her', 'hers', 'herself',\n",
      "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
      "                ('mb', MultinomialNB())])\n",
      "\n",
      "SVC: \n",
      "Pipeline(steps=[('tvec',\n",
      "                 TfidfVectorizer(max_df=0.85, max_features=4000, min_df=0.002)),\n",
      "                ('svc', SVC())])\n"
     ]
    }
   ],
   "source": [
    "# best estimators\n",
    "\n",
    "print(f'Multinomial Naive Bayes: \\n{gs_mb_t.best_estimator_}')\n",
    "print(f'\\nSVC: \\n{gs_svc_t.best_estimator_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes: \n",
      "{'tvec__max_df': 0.85, 'tvec__max_features': 4000, 'tvec__min_df': 0.003, 'tvec__ngram_range': (1, 1), 'tvec__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn', 'co', 'pm', 'wa', 'edt', 'amp', 'ha', 'cdt', 'one', 'state', 'hurricane', 'laura', 'hurricanelaura', 'trump', 'texas', 'louisiana', 'tx', 'houston'], 'score': 0.8987644369108739}\n",
      "\n",
      "SVC: \n",
      "{'tvec__max_df': 0.85, 'tvec__max_features': 4000, 'tvec__min_df': 0.002, 'tvec__ngram_range': (1, 1), 'tvec__stop_words': None, 'score': 0.990697708723005}\n"
     ]
    }
   ],
   "source": [
    "# best parameters\n",
    "\n",
    "print(f'Multinomial Naive Bayes: \\n{gs_mb_t.best_params_}')\n",
    "print(f'\\nSVC: \\n{gs_svc_t.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "\n",
    "y_preds_t = gs_svc_t.predict(X_test)\n",
    "\n",
    "# confusion matrix values\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_preds_t).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAEKCAYAAABzM8J8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZgElEQVR4nO3deZgV1Z3/8fenu0EFWVRAkUVRiYI7MG6MjvtAEvXnllHjGBPnR4xRs2keM5OoIckviU7GmTg4CVF+RE1kdNTYRhRxCxrRsIgLuCGKLCogiLtI850/bjVeOvS9t6Qvt7r683qeerxVde6pc+Hxw6nlnFJEYGaWF3W1boCZWVtyqJlZrjjUzCxXHGpmlisONTPLFYeameWKQ83MakbSBEnLJD3Tyn5J+qWk+ZKekjSsXJ0ONTOrpYnAqBL7RwODk2UM8F/lKnSomVnNRMQ0YGWJIicA10fBY0BPSX1L1dnQlg3cVGrYKtS5W62bYSnsP2RgrZtgKSxc+AorVqzQptRR332niLUfVFQ2Plg+F/iwaNP4iBif4nD9gEVF64uTba+19oVshVrnbmyx+xdq3QxL4c+P/2etm2ApjDxwxCbXEWs/qPj/0w/njPswIjb9oClkKtTMrD0QaLNduVoCDCha759sa5WvqZlZOgLq6itbNl0jcFZyF/QgYHVEtHrqCe6pmdmnoU26LFdUjW4CDgd6SVoMXAZ0AoiIXwGTgc8C84H3gS+Xq9OhZmYptd3pZ0ScXmZ/AF9PU6dDzczSa6OeWjU41MwsHbE5bxSk5lAzs5TknpqZ5Uzb3NmsCoeamaW0WZ9TS82hZmbpCJ9+mlnOuKdmZvnh008zyxMB9b5RYGZ54mtqZpYfPv00s7xxT83McsU9NTPLDXmYlJnljYdJmVl++EaBmeWNTz/NLDc8n5qZ5YtPP80sb3yjwMxyxdfUzCw35NNPM8sb99TMLE/kUDOzvCjM5u1QM7O8kFCdQ83McsQ9NTPLFYeameWKQ83M8kPJklEONTNLRcg9NTPLl7o6jygwsxxxT83M8sPX1Mwsb7LcU8vuibGZZVLzjYJKlrJ1SaMkPS9pvqRLNrJ/oKQHJT0h6SlJny1Xp0PNzFJTnSpaStYh1QPjgNHAUOB0SUNbFPs+cHNE7A+cBlxTrm0ONTNLR7RVT+0AYH5ELIiINcAk4IQWZQLonnzuASwtV6mvqZlZaimuqfWSNLNofXxEjE8+9wMWFe1bDBzY4vuXA/dKugDoChxd7oAONTNLLUWorYiIEZtwqNOBiRHxC0kHAzdI2isi1rX2BYeamaXShiMKlgADitb7J9uKnQOMAoiI6ZK2BHoBy1qr1NfUzCw9VbiUNgMYLGmQpM4UbgQ0tijzKnAUgKQhwJbA8lKVuqdmZumobYZJRcRaSecDU4B6YEJEzJU0FpgZEY3Ad4DfSPoWhZsGZ0dElKrXoWZmqbXVw7cRMRmY3GLbpUWf5wEj09TpUDOz9LI7oMDX1Krp6h98kRem/JRHJ/1zrZtiFbrv0Xn8zcljGXbi5Vw18d5aNyez2mpEQTVUNdTKDYHIu5v++BinXDiu1s2wCjU1rePiK27mlv84j8du/j633juL5xa8VutmZU6lgZa7UKtwCESuPfrES6x6+/1aN8MqNGvuK+wyoBc79+9F504NnHTMMCb/6alaNyuTOmSoUdkQCLPMeG35avptv8369R2334bXlq+uYYuyqy3GflZLNW8UVDIEAkljgDEAdNq6is0xs7aS5amHan73MxkHNh6grkufks+fmFVT3949WPLGqvXrS99YRd/ePWrYooxStkOtmqeflQyBMMuMYUN34qVXl7NwyQrWfLyW26bOZvRh+9S6WZkjQKpsqYVq9tTWD4GgEGanAWdU8XiZc+2Pz2bk8MFs13Nrnvnjj/jZ+Mnc2Di91s2yVjQ01HPFd7/AyReOo6kp+OLxBzFk1761blYGddC3SbU2BKJax8uif/r+xFo3wVI6duSeHDtyz1o3I/PqanQToBJVvaa2sSEQZtbO1fDUshI1v1FgZu2L6MA9NTPLJ/fUzCxXOuSNAjPLKV9TM7M8EWqTSSKrxaFmZqm5p2ZmueJramaWH76mZmZ5Uhj7md1Uc6iZWWoZzjSHmpml5xEFZpYfGZ9PzaFmZqk0z6eWVQ41M0upg86nZmb5leFMc6iZWUryjQIzyxE/p2ZmueNQM7NcyXCmOdTMLD331MwsPzyg3czypDBJZHZTzaFmZqnVZbirlt05ec0ss6TKlvL1aJSk5yXNl3RJK2W+IGmepLmSfl+uTvfUzCwVtdGAdkn1wDjgGGAxMENSY0TMKyozGPgeMDIiVknqU65e99TMLLU6VbaUcQAwPyIWRMQaYBJwQosy/xcYFxGrACJiWblKW+2pSboaiNb2R8SFZZtsZrmU4kZBL0kzi9bHR8T45HM/YFHRvsXAgS2+/xkASX8G6oHLI+KeUgcsdfo5s8Q+M+ugROEOaIVWRMSITThcAzAYOBzoD0yTtHdEvFXqCxsVEb8tXpfUJSLe34TGmVlOtNETHUuAAUXr/ZNtxRYDj0fEx8DLkl6gEHIzWm1buaNKOljSPOC5ZH1fSdekbLyZ5YUK86lVspQxAxgsaZCkzsBpQGOLMn+g0EtDUi8Kp6MLSlVayY2Cfwf+HngTICKeBA6r4HtmllNt8UhHRKwFzgemAM8CN0fEXEljJR2fFJsCvJl0rB4ELo6IN0vVW9EjHRGxqEXqNlXyPTPLH9F2D99GxGRgcottlxZ9DuDbyVKRSkJtkaRDgJDUCfgGhVQ1sw4qy8OkKjn9PBf4OoXbr0uB/ZJ1M+uAKj31rNVIqrI9tYhYAXxxM7TFzNqJdj32U9Iuku6UtFzSMkl3SNplczTOzLJJFS61UMnp5++Bm4G+wI7ALcBN1WyUmWVbGz3SURWVhFqXiLghItYmy43AltVumJllU+HuZ5uM/ayKUmM/t00+3p1MCTKJwljQf6DFLVgz60DUfieJnEUhxJpb/9WifUFhOhAz64Da5TsKImLQ5myImbUPzaefWVXRiAJJewFDKbqWFhHXV6tRZpZt7bKn1kzSZRQGlA6lcC1tNPAI4FAz66CyG2mV3f08BTgKeD0ivgzsC/SoaqvMLLMkqK9TRUstVHL6+UFErJO0VlJ3YBkbzoFkZh1Muz79BGZK6gn8hsId0XeB6dVslJllW4YzraKxn+clH38l6R6ge0Q8Vd1mmVlWCWV67Geph2+HldoXEbOr0yQzy7QazsBRiVI9tV+U2BfAkW3cFvYbMpBHpl/d1tVaFW1z4Ddq3QRL4aPnFpUvVIF2eU0tIo7YnA0xs/ZBQH17DDUzs9a0+xEFZmbFHGpmlhuFqbqzm2qVzHwrSWdKujRZHyjpgOo3zcyyKsvzqVUyTOoa4GDg9GT9HWBc1VpkZpnXrl+8AhwYEcMkPQEQEauStymbWQckoCHDp5+VhNrHkuopPJuGpN7Auqq2yswyLcOZVlGo/RK4Hegj6ScUZu34flVbZWaZJbXTYVLNIuJ3kmZRmH5IwP+JCL+h3awDy3CmVTRJ5EDgfeDO4m0R8Wo1G2Zm2dXen1O7i09ewLIlMAh4Htiziu0ys4wS1GwCyEpUcvq5d/F6MnvHea0UN7O8q+EzaJVIPaIgImZLOrAajTGz9kEZfktBJdfUvl20WgcMA5ZWrUVmlml5eEVet6LPaylcY7u1Os0xs/ag3YZa8tBtt4i4aDO1x8zagSwPaC81nXdDRKyVNHJzNsjMsq3wirxat6J1pZr2l+S/cyQ1SvpHSSc1L5ujcWaWTXXJqIJySzmSRkl6XtJ8SZeUKHeypJA0olydlVxT2xJ4k8I7CZqfVwvgtgq+a2Y501Y3CpLLW+OAY4DFwAxJjRExr0W5bsA3gMcrqbdUqPVJ7nw+wydh1ixStN3McqaNLqkdAMyPiAWFOjUJOAGY16Lcj4CfAxdXUmmp0896YOtk6Vb0uXkxsw5J1FW4AL0kzSxaxhRV1A8ofr3V4mTbJ0cqPOw/ICLuqrR1pXpqr0XE2EorMrOOQaTqqa2IiLLXwTZ6HKkO+Dfg7DTfKxVq2b1na2a1I2homwfVlgADitb7J9uadQP2Ah5KHiHZAWiUdHxEzGyt0lKhdtSnb6uZ5VXKnlopM4DBkgZRCLPTgDOad0bEaqDX+uNKDwEXlQo0KP0y45Wb2GAzy6m2mCQyeQ72fGAKhWv4EyJirqSxwMyIaPw09foVeWaWWlsNKIiIycDkFtsubaXs4ZXU6VAzs1REZa+hqxWHmpmlo7Y5/awWh5qZpVIYUeBQM7McyW6kOdTM7FPIcEfNoWZmaal9zqdmZrYxvvtpZrnjGwVmlh9qp9N5m5ltjE8/zSx33FMzs1zJbqQ51MwsJQH17qmZWZ5kONMcamaWllCGT0AdamaWmntqZpYbhUc6sptqDjUzS0fuqZlZzniYlJnlRmGSyFq3onUONTNLzXc/zSxXMnz26VCrxP3T5/G9f7uVdevWcebxB/PNLx27wf6P1nzMeT+8gSefW8Q2Pbpy3Y+/zMAdtwPgqon38rs7p1NXV8fPvnMKRx40BIBfT3qI6+94lIjgrBMO4dzTjwDgnH+ZwPyFywBY/e4H9Nh6K/504yWb8dfm21EH7cFPv30S9XV13ND4GP9+/X0b7B+wwzZc/f0z6NVza1a9/R5fvfwGli5bDcDlXz+OY0fuCcCVE6Zw+31PbPb2Z0WH7KlJmgB8HlgWEXtV6zjV1tS0ju9eeQu3Xv11duzTk6PPvpJRh+7NHrv0XV/mxsbp9OzWhZm3XsZt987ih+Pu4LqffIXnFrzG7VNn8eeb/pnXV6zmpPPH8ZdbfsALr7zO9Xc8ytT/fxGdG+o59ZvXcOzf7sUuA3pz3U++sr7eH/zHbXTvulUtfnYu1dWJKy8+lRMvuIaly97igYnf4e6Hn+b5l99YX2bshScwafJfmDR5BocOH8yl5x3HuZffyLEjh7LP7gM49B+vYItODdz5Xxdw3/R5vPPeRzX8RbWR9Wtq1ZxBZCIwqor1bxaz5y1kUP9e7NyvF507NXDiMcO5e9rTG5S5e9rTnPa5AwE4/sj9mDbjBSKCu6c9zYnHDGeLzp3YacdeDOrfi9nzFvLCK28wfM+d6LJlZxoa6hm5/2D++NCTG9QZEfzhvic46djhm+235t3woTuxYPFyFi59k4/XNnHb1Nl89rC9Nyiz+6AdeHjmiwA8POtFRif7dx+0A4/OmU9T0zre/3ANc+cv5aik193hSNRVuNRC1UItIqYBK6tV/+by2rK36Lf9NuvXd+zTk9eWv7VhmeWr2bFPTwAaGurpvvVWrFz9Hq8t38h3l73FHrv05bE5L7Fy9Xu8/+Eapj46lyVvrNqgzulzXqL3tt3YdWCfqv22jqZvnx4seeOt9etLl71F3949Nigz98WlfP6IfQH4/OH70L3rlmzTvQvPvLiEow8awlZbdGLbHl05dPhuG/zddjSqcKmFml9TkzQGGAMwYODAGrdm89h90A5ceNYxnHLBOLps1Zm9PtOf+roN/3259d5ZnOxe2mb3g1/+gSsuOoUzPncAj855iSXL3qJpXfDg488zbMhAplz7TVaseo8ZT79C07p1tW5uTfi9n2VExHhgPMCw4SOixs35K3379NygF1X4173nhmV692Bp0qNbu7aJt9/9gG17dKVv7418N+nRnXn8wZx5/MEA/OiaxvU9PYC1a5u468Enuf+3F1ftd3VEry1bTb/te65fL/S6V29Q5vUVb3PWJRMA6LpVZ447Yl/efvcDAH4xcSq/mDgVgN+MPYuXXl2+eRqeQdmNtGzPypsJ+w8ZyIJFy1m4dAVrPl7L7VNnrb/O0mzUoXsz6a7HAWh8YA6HjvgMkhh92N7cPnUWH635mIVLV7Bg0XKGDd0JgOUr3wFg8esr+eNDT3LK349YX9+fZjzP4J2379CnN9Uw+9lX2XVAbwb23ZZODfWcdMww7p72zAZltu3Rdf2srt/60jH87s7HgMJNhm26dwFgz912ZM/dduSBx5/bvD8gSzJ8/lnznlrWNTTU8/OLTuXUC6+haV1wxnEHsccuffnpr+9ivyEDGX3Y3px5/MF87fLrGXHyD+nZvQvX/vjLAOyxS19OOHoYh5z2/6ivr+OKi0+lvr7w78jZl1zLytXv06mhjisu/gI9unVZf8zbps7yDYIqaGpax3f/9VZu/eXXqK+r43d3PsZzL7/O98aMZs6zi7j74Wf42+G7cel5xxERPPrES1x85S0AdGqoZ/L4bwDwznsfMuayG2hq6pinn5Dt009FVOeMT9JNwOFAL+AN4LKIuK7Ud4YNHxGPTJ9RlfZYdWx38Ddr3QRL4aPnJrHuvTc2KZGG7L1/XH/HQxWVPWDXnrMiYkT5km2naj21iDi9WnWbWY1lt6Pm008zS6dwuSy7qeZQM7N0Mj6fmu9+mllqbXXzU9IoSc9Lmi/prwY5S/q2pHmSnpJ0v6SdytXpUDOzlIRU2VKyFqkeGAeMBoYCp0sa2qLYE8CIiNgH+B/ginKtc6iZWWpSZUsZBwDzI2JBRKwBJgEnFBeIiAcj4v1k9TGgf7lKHWpmlkqlp55JpvWSNLNoGVNUVT9gUdH64mRba84B7i7XPt8oMLP0Kr9RsKItnlOTdCYwAvi7cmUdamaWWhs90rEEGFC03j/ZtuGxpKOBfwH+LiLKTmDn008zS62NrqnNAAZLGiSpM3Aa0LjhcbQ/8Gvg+IhYVknb3FMzs3Ta6Dm1iFgr6XxgClAPTIiIuZLGAjMjohG4EtgauCW5m/pqRBxfql6Hmpml1lYjCiJiMjC5xbZLiz4fnbZOh5qZpSKyPaLAoWZmqWU40xxqZvYpZDjVHGpmllqWJ4l0qJlZatmNNIeamX0aGU41h5qZpeJJIs0sXzI+SaRDzcxSy3CmOdTMLK3yE0DWkkPNzFLLcKY51MwsnRq+fL0iDjUzSy/DqeZQM7PU/EiHmeWKr6mZWX4I6hxqZpYv2U01h5qZpeJJIs0sdzKcaQ41M0vPPTUzyxUPkzKzXMlupDnUzCylCl9UXDMONTNLzSMKzCxfsptpDjUzSy/DmeZQM7O05FfkmVl+ZH1EQV2tG2Bm1pbcUzOz1LLcU3OomVlqfqTDzPLDD9+aWZ5k/UaBQ83MUvPpp5nlSpZ7an6kw8xSU4VL2XqkUZKelzRf0iUb2b+FpP9O9j8uaedydTrUzCy9Nkg1SfXAOGA0MBQ4XdLQFsXOAVZFxG7AVcDPyzXNoWZmqQiokypayjgAmB8RCyJiDTAJOKFFmROA3yaf/wc4SmVmqMzUNbUnZs9a0XWLuoW1bkcV9AJW1LoRlkpe/8522tQKZs+eNWWrTupVYfEtJc0sWh8fEeOTz/2ARUX7FgMHtvj++jIRsVbSamA7SvzdZCrUIqJ3rdtQDZJmRsSIWrfDKue/s9ZFxKhat6EUn36aWa0sAQYUrfdPtm20jKQGoAfwZqlKHWpmViszgMGSBknqDJwGNLYo0wh8Kfl8CvBARESpSjN1+plj48sXsYzx31mVJdfIzgemAPXAhIiYK2ksMDMiGoHrgBskzQdWUgi+klQm9MzM2hWffppZrjjUzCxXHGpVVG4IiGWPpAmSlkl6ptZtsU/HoVYlFQ4BseyZCGT6OSwrzaFWPZUMAbGMiYhpFO6yWTvlUKuejQ0B6Vejtph1GA41M8sVh1r1VDIExMzamEOteioZAmJmbcyhViURsRZoHgLyLHBzRMytbausHEk3AdOB3SUtlnROrdtk6XiYlJnlintqZpYrDjUzyxWHmpnlikPNzHLFoWZmueJQa0ckNUmaI+kZSbdI6rIJdU2UdEry+dpSg+0lHS7pkE9xjFekv37rUGvbW5R5N+WxLpd0Udo2Wv441NqXDyJiv4jYC1gDnFu8M3kxRWoR8U8RMa9EkcOB1KFmVgsOtfbrYWC3pBf1sKRGYJ6keklXSpoh6SlJXwVQwX8m87vdB/RprkjSQ5JGJJ9HSZot6UlJ90vamUJ4fivpJR4qqbekW5NjzJA0MvnudpLulTRX0rWUfUc3SPqDpFnJd8a02HdVsv1+Sb2TbbtKuif5zsOS9miTP03LDb94pR1KemSjgXuSTcOAvSLi5SQYVkfE30jaAvizpHuB/YHdKczttj0wD5jQot7ewG+Aw5K6to2IlZJ+BbwbEf+alPs9cFVEPCJpIIVRE0OAy4BHImKspM8BlTyN/5XkGFsBMyTdGhFvAl0pvHzjW5IuTeo+n8ILUc6NiBclHQhcAxz5Kf4YLaccau3LVpLmJJ8fpvCmnUOAv0TEy8n2Y4F9mq+XUXhP4mDgMOCmiGgClkp6YCP1HwRMa64rIlqbV+xoYKi0viPWXdLWyTFOSr57l6RVFfymCyWdmHwekLT1TWAd8N/J9huB25JjHALcUnTsLSo4hnUgDrX25YOI2K94Q/I/93vFm4ALImJKi3KfbcN21AEHRcSHG2lLxSQdTiEgD46I9yU9BGzZSvFIjvtWyz8Ds2K+ppY/U4CvSeoEIOkzkroC04B/SK659QWO2Mh3HwMOkzQo+e62yfZ3gG5F5e4FLmhekbRf8nEacEaybTSwTZm29gBWJYG2B4WeYrM6Ci+vJanzkYh4G3hZ0qnJMSRp3zLHsA7GoZY/11K4XjY7eXnIryn0yG8HXkz2XU9hJooNRMRyYAyFU70n+eT0707gxOYbBcCFwIjkRsQ8PrkL+0MKoTiXwmnoq2Xaeg/QIOlZ4GcUQrXZe8AByW84EhibbP8icE7Svrl4inRrwbN0mFmuuKdmZrniUDOzXHGomVmuONTMLFccamaWKw41M8sVh5qZ5cr/AoqEZWkfmx20AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view confusion matrix\n",
    "\n",
    "plot_confusion_matrix(gs_svc_t, X_test, y_test, cmap = 'Blues', normalize = 'true');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### word2vec\n",
    "#### Multinomial Naive Bayes and Support Vector Machine\n",
    "#> Multinomial Naive Bayes did not work because of negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim and create a model to vectorize the words\n",
    "\n",
    "import gensim\n",
    "\n",
    "file_path = '../vectors/lexvec.enwiki+newscrawl.300d.W.pos.vectors'\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### with stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list to store mean vector values from each row\n",
    "\n",
    "vectors = [] \n",
    "\n",
    "# iterate through each row\n",
    "for i in range(len(df['text_clean'])):\n",
    "    \n",
    "    # create an empty list to store vector values of each row\n",
    "    vector = []\n",
    "    \n",
    "    # iterate through each word of each row\n",
    "    for word in df['text_clean'][i].split(' '): \n",
    "        \n",
    "        if word not in stop_words: \n",
    "        \n",
    "            # if word is present in model, then vectorize\n",
    "            try:\n",
    "                word_vec = model[word] \n",
    "                # if word is present then append it to temporary dataframe\n",
    "                vector.append(word_vec) \n",
    "        \n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    vectors.append(np.mean(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41076\n",
      "41076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0027685475, 0.006268722, 0.00063196605]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if vectors have been created\n",
    "\n",
    "print(len(df['text_clean']))\n",
    "print(len(vectors))\n",
    "vectors[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store vector values in the dataframe\n",
    "\n",
    "df['vector_mean'] = vectors\n",
    "\n",
    "# if null, fill null value as 0 --> foreign language still in UTF8 format\n",
    "\n",
    "df['vector_mean'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting X and y\n",
    "\n",
    "X = df[['vector_mean']]\n",
    "y = df['label']\n",
    "\n",
    "\n",
    "# train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5888905281794039"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "# fit\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "# score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list to store mean vector values from each row\n",
    "\n",
    "vectors = [] \n",
    "\n",
    "# iterate through each row\n",
    "for i in range(len(df['text_clean'])):\n",
    "    \n",
    "    # create an empty list to store vector values of each row\n",
    "    vector = []\n",
    "    \n",
    "    # iterate through each word of each row\n",
    "    for word in df['text_clean'][i].split(' '): \n",
    "        \n",
    "        try:\n",
    "            word_vec = model[word] \n",
    "            vector.append(word_vec) \n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    vectors.append(np.mean(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41076\n",
      "41076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.0706724e-05, 0.0032079108, -0.0008800765]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if vectors have been created\n",
    "\n",
    "print(len(df['text_clean']))\n",
    "print(len(vectors))\n",
    "vectors[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store vector values in the dataframe\n",
    "\n",
    "df['vector1_mean'] = vectors\n",
    "\n",
    "# if null, fill null value as 0 --> foreign languages still in UTF8 format\n",
    "\n",
    "df['vector1_mean'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting X and y\n",
    "\n",
    "X = df[['vector1_mean']]\n",
    "y = df['label']\n",
    "\n",
    "\n",
    "# train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.564030687518442"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "# fit\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "# score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
