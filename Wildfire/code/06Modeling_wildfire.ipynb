{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook models wildfire data with NB and SVC supervised mode\n",
    "Code adapted from group member Juhee Sung-Schenck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19999, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>n_sentence</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1305657570774978560</td>\n",
       "      <td>FireandAviation</td>\n",
       "      <td>37.280386</td>\n",
       "      <td>-122.128109</td>\n",
       "      <td>2020-09-14 23:59:57+00:00</td>\n",
       "      <td>Smoke from California wildfires causes hazy sk...</td>\n",
       "      <td>smoke from california wildfire cause hazy sky ...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1304359517552095235</td>\n",
       "      <td>JoinDeepRock</td>\n",
       "      <td>36.052556</td>\n",
       "      <td>-119.406770</td>\n",
       "      <td>2020-09-11 10:01:57+00:00</td>\n",
       "      <td>96% Overwhelmingly Positive Reviews! Grab a fr...</td>\n",
       "      <td>overwhelmingly positive review  grab a frien...</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1305657551703412736</td>\n",
       "      <td>matthew_paul17</td>\n",
       "      <td>35.839572</td>\n",
       "      <td>-122.243498</td>\n",
       "      <td>2020-09-14 23:59:52+00:00</td>\n",
       "      <td>So a 2-3 degree temperature difference is what...</td>\n",
       "      <td>so a   degree temperature difference is what c...</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1305657540227850240</td>\n",
       "      <td>Josie95450522</td>\n",
       "      <td>34.897778</td>\n",
       "      <td>-119.722077</td>\n",
       "      <td>2020-09-14 23:59:50+00:00</td>\n",
       "      <td>@POTUS is right about the #wildfires Expert in...</td>\n",
       "      <td>potus is right about the wildfires expert inve...</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1305657538281533440</td>\n",
       "      <td>Arqahn</td>\n",
       "      <td>38.370841</td>\n",
       "      <td>-120.107434</td>\n",
       "      <td>2020-09-14 23:59:49+00:00</td>\n",
       "      <td>Wildfires in California ARE caused by poor lan...</td>\n",
       "      <td>wildfire in california are caused by poor land...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id        user_name        lat        long  \\\n",
       "0  1305657570774978560  FireandAviation  37.280386 -122.128109   \n",
       "1  1304359517552095235     JoinDeepRock  36.052556 -119.406770   \n",
       "2  1305657551703412736   matthew_paul17  35.839572 -122.243498   \n",
       "3  1305657540227850240    Josie95450522  34.897778 -119.722077   \n",
       "4  1305657538281533440           Arqahn  38.370841 -120.107434   \n",
       "\n",
       "                        date  \\\n",
       "0  2020-09-14 23:59:57+00:00   \n",
       "1  2020-09-11 10:01:57+00:00   \n",
       "2  2020-09-14 23:59:52+00:00   \n",
       "3  2020-09-14 23:59:50+00:00   \n",
       "4  2020-09-14 23:59:49+00:00   \n",
       "\n",
       "                                                text  \\\n",
       "0  Smoke from California wildfires causes hazy sk...   \n",
       "1  96% Overwhelmingly Positive Reviews! Grab a fr...   \n",
       "2  So a 2-3 degree temperature difference is what...   \n",
       "3  @POTUS is right about the #wildfires Expert in...   \n",
       "4  Wildfires in California ARE caused by poor lan...   \n",
       "\n",
       "                                          text_clean  n_sentence  n_words  \n",
       "0  smoke from california wildfire cause hazy sky ...           1        9  \n",
       "1    overwhelmingly positive review  grab a frien...           2       15  \n",
       "2  so a   degree temperature difference is what c...           1       36  \n",
       "3  potus is right about the wildfires expert inve...           2       39  \n",
       "4  wildfire in california are caused by poor land...           1        9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in csv\n",
    "\n",
    "df = pd.read_csv('../data/final.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "user_name     0\n",
       "lat           0\n",
       "long          0\n",
       "date          0\n",
       "text          0\n",
       "text_clean    0\n",
       "n_sentence    0\n",
       "n_words       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about 3 percent of cleaned text are missing\n",
    "# it could be due to non-english tweets that I did not know how to process in cleaning stage \n",
    "# will drop these rows\n",
    "\n",
    "df.dropna(axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make your own relevant words here\n",
    "# make a list of words that would automatically tag a word as relevant\n",
    "\n",
    "relevant_words = ['wildfire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to create a list of 1s and 0s\n",
    "\n",
    "def create_target(column):    \n",
    "    \n",
    "    labels = []\n",
    "    \n",
    "    # separate each row\n",
    "    for text in column:\n",
    "        \n",
    "        # initiate 0 as label\n",
    "        label = 0\n",
    "        \n",
    "        # iterate through words in relevant_words\n",
    "        for relevant_word in relevant_words:\n",
    "            \n",
    "            # if relevant_word is found in text, assign 1 as label\n",
    "            # stop comparing once assigned as 1, then append it to the list\n",
    "            if relevant_word in text:\n",
    "                label = 1\n",
    "                break\n",
    "        labels.append(label)\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4705235261763088"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the label is created as expected (if about 50%, then it's good!)\n",
    "\n",
    "np.mean(create_target(df['text_clean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a column in the dataframe to capture this information\n",
    "\n",
    "df['label'] = create_target(df['text_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>n_sentence</th>\n",
       "      <th>n_words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1305657570774978560</td>\n",
       "      <td>FireandAviation</td>\n",
       "      <td>37.280386</td>\n",
       "      <td>-122.128109</td>\n",
       "      <td>2020-09-14 23:59:57+00:00</td>\n",
       "      <td>Smoke from California wildfires causes hazy sk...</td>\n",
       "      <td>smoke from california wildfire cause hazy sky ...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1304359517552095235</td>\n",
       "      <td>JoinDeepRock</td>\n",
       "      <td>36.052556</td>\n",
       "      <td>-119.406770</td>\n",
       "      <td>2020-09-11 10:01:57+00:00</td>\n",
       "      <td>96% Overwhelmingly Positive Reviews! Grab a fr...</td>\n",
       "      <td>overwhelmingly positive review  grab a frien...</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1305657551703412736</td>\n",
       "      <td>matthew_paul17</td>\n",
       "      <td>35.839572</td>\n",
       "      <td>-122.243498</td>\n",
       "      <td>2020-09-14 23:59:52+00:00</td>\n",
       "      <td>So a 2-3 degree temperature difference is what...</td>\n",
       "      <td>so a   degree temperature difference is what c...</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1305657540227850240</td>\n",
       "      <td>Josie95450522</td>\n",
       "      <td>34.897778</td>\n",
       "      <td>-119.722077</td>\n",
       "      <td>2020-09-14 23:59:50+00:00</td>\n",
       "      <td>@POTUS is right about the #wildfires Expert in...</td>\n",
       "      <td>potus is right about the wildfires expert inve...</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1305657538281533440</td>\n",
       "      <td>Arqahn</td>\n",
       "      <td>38.370841</td>\n",
       "      <td>-120.107434</td>\n",
       "      <td>2020-09-14 23:59:49+00:00</td>\n",
       "      <td>Wildfires in California ARE caused by poor lan...</td>\n",
       "      <td>wildfire in california are caused by poor land...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id        user_name        lat        long  \\\n",
       "0  1305657570774978560  FireandAviation  37.280386 -122.128109   \n",
       "1  1304359517552095235     JoinDeepRock  36.052556 -119.406770   \n",
       "2  1305657551703412736   matthew_paul17  35.839572 -122.243498   \n",
       "3  1305657540227850240    Josie95450522  34.897778 -119.722077   \n",
       "4  1305657538281533440           Arqahn  38.370841 -120.107434   \n",
       "\n",
       "                        date  \\\n",
       "0  2020-09-14 23:59:57+00:00   \n",
       "1  2020-09-11 10:01:57+00:00   \n",
       "2  2020-09-14 23:59:52+00:00   \n",
       "3  2020-09-14 23:59:50+00:00   \n",
       "4  2020-09-14 23:59:49+00:00   \n",
       "\n",
       "                                                text  \\\n",
       "0  Smoke from California wildfires causes hazy sk...   \n",
       "1  96% Overwhelmingly Positive Reviews! Grab a fr...   \n",
       "2  So a 2-3 degree temperature difference is what...   \n",
       "3  @POTUS is right about the #wildfires Expert in...   \n",
       "4  Wildfires in California ARE caused by poor lan...   \n",
       "\n",
       "                                          text_clean  n_sentence  n_words  \\\n",
       "0  smoke from california wildfire cause hazy sky ...           1        9   \n",
       "1    overwhelmingly positive review  grab a frien...           2       15   \n",
       "2  so a   degree temperature difference is what c...           1       36   \n",
       "3  potus is right about the wildfires expert inve...           2       39   \n",
       "4  wildfire in california are caused by poor land...           1        9   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      0  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this to a csv file\n",
    "\n",
    "df.to_csv('../data/final_labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.529476\n",
       "1    0.470524\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define baseline accuracy\n",
    "\n",
    "df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up X and y and train test split\n",
    "\n",
    "X = df['text_clean']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .33, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "# create a custom stop words list\n",
    "\n",
    "print(len(stopwords.words('english')))\n",
    "\n",
    "stop_words = stopwords.words('english') + relevant_words\n",
    "\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer()\n",
    "#### Multinomial Naive Bayes and Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set 2 pipelines with: 1. Multinomial Bayes 2. Support Vector Machine\n",
    "\n",
    "pipeline_mb = Pipeline([\n",
    "                       ('cvec', CountVectorizer()),\n",
    "                       ('mb', MultinomialNB())\n",
    "                       ])\n",
    "\n",
    "pipeline_svc = Pipeline([\n",
    "                        ('cvec', CountVectorizer()),\n",
    "                        ('svc', SVC())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dictionary to store the best parameters\n",
    "\n",
    "model_mb_params = {}\n",
    "count_mb = 0\n",
    "\n",
    "model_svc_params = {}\n",
    "count_svc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up parameters\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [3000, 4000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.85, .90],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)],\n",
    "    'cvec__stop_words': [stop_words]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate GridSearchCV - NaiveBayes\n",
    "\n",
    "gs_mb = GridSearchCV(pipeline_mb, \n",
    "                     param_grid = pipe_params, \n",
    "                     cv = 3) \n",
    "\n",
    "# instantiate GridSearchCV - SVC\n",
    "\n",
    "gs_svc = GridSearchCV(pipeline_svc, \n",
    "                      param_grid = pipe_params, \n",
    "                      cv = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase counter as we put in different parameters\n",
    "\n",
    "count_mb += 1\n",
    "\n",
    "# fit the training set\n",
    "\n",
    "gs_mb.fit(X_train, y_train)\n",
    "\n",
    "# best score is not captured in parameters -> create a key 'score' to store the info\n",
    "\n",
    "gs_mb.best_params_['score'] = gs_mb.best_score_\n",
    "\n",
    "model_mb_params[f'model_{count_mb}'] = gs_mb.best_params_\n",
    "\n",
    "# dictionary to a dataframe\n",
    "\n",
    "model_mb_df = pd.DataFrame.from_dict(model_mb_params, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvec__max_df</th>\n",
       "      <th>cvec__max_features</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>cvec__ngram_range</th>\n",
       "      <th>cvec__stop_words</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>0.919098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cvec__max_df  cvec__max_features  cvec__min_df cvec__ngram_range  \\\n",
       "model_1          0.85                4000             2            (1, 2)   \n",
       "\n",
       "                                          cvec__stop_words     score  \n",
       "model_1  [i, me, my, myself, we, our, ours, ourselves, ...  0.919098  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase counter as we put in different parameters\n",
    "\n",
    "count_svc += 1\n",
    "\n",
    "# fit the training set\n",
    "\n",
    "gs_svc.fit(X_train, y_train)\n",
    "\n",
    "# best score is not captured in parameters -> create a key 'score' to store the info\n",
    "\n",
    "gs_svc.best_params_['score'] = gs_svc.best_score_\n",
    "\n",
    "model_svc_params[f'model_{count_svc}'] = gs_svc.best_params_\n",
    "\n",
    "# dictionary to a dataframe\n",
    "\n",
    "model_svc_df = pd.DataFrame.from_dict(model_svc_params, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvec__max_df</th>\n",
       "      <th>cvec__max_features</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>cvec__ngram_range</th>\n",
       "      <th>cvec__stop_words</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>4000</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>0.936712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cvec__max_df  cvec__max_features  cvec__min_df cvec__ngram_range  \\\n",
       "model_1          0.85                4000             3            (1, 2)   \n",
       "\n",
       "                                          cvec__stop_words     score  \n",
       "model_1  [i, me, my, myself, we, our, ours, ourselves, ...  0.936712  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes: 0.935144413762221\n",
      "\n",
      "SVC: 0.9761922531532203\n"
     ]
    }
   ],
   "source": [
    "# train set score\n",
    "\n",
    "print(f'Multinomial Naive Bayes: {gs_mb.score(X_train, y_train)}')\n",
    "print(f'\\nSVC: {gs_svc.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes: 0.9177272727272727\n",
      "\n",
      "SVC: 0.9407575757575758\n"
     ]
    }
   ],
   "source": [
    "# test set score\n",
    "\n",
    "print(f'Multinomial Naive Bayes: {gs_mb.score(X_test, y_test)}')\n",
    "print(f'\\nSVC: {gs_svc.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes: \n",
      "{'cvec__max_df': 0.85, 'cvec__max_features': 4000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'wildfire'], 'score': 0.9190984337113423}\n",
      "\n",
      "SVC: \n",
      "{'cvec__max_df': 0.85, 'cvec__max_features': 4000, 'cvec__min_df': 3, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'wildfire'], 'score': 0.9367118334372452}\n"
     ]
    }
   ],
   "source": [
    "# find the best parameters for both models\n",
    "\n",
    "print(f'Multinomial Naive Bayes: \\n{gs_mb.best_params_}')\n",
    "print(f'\\nSVC: \\n{gs_svc.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes: \n",
      "Pipeline(steps=[('cvec',\n",
      "                 CountVectorizer(max_df=0.85, max_features=4000, min_df=2,\n",
      "                                 ngram_range=(1, 2),\n",
      "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
      "                                             'our', 'ours', 'ourselves', 'you',\n",
      "                                             \"you're\", \"you've\", \"you'll\",\n",
      "                                             \"you'd\", 'your', 'yours',\n",
      "                                             'yourself', 'yourselves', 'he',\n",
      "                                             'him', 'his', 'himself', 'she',\n",
      "                                             \"she's\", 'her', 'hers', 'herself',\n",
      "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
      "                ('mb', MultinomialNB())])\n",
      "\n",
      "SVC: \n",
      "Pipeline(steps=[('cvec',\n",
      "                 CountVectorizer(max_df=0.85, max_features=4000, min_df=3,\n",
      "                                 ngram_range=(1, 2),\n",
      "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
      "                                             'our', 'ours', 'ourselves', 'you',\n",
      "                                             \"you're\", \"you've\", \"you'll\",\n",
      "                                             \"you'd\", 'your', 'yours',\n",
      "                                             'yourself', 'yourselves', 'he',\n",
      "                                             'him', 'his', 'himself', 'she',\n",
      "                                             \"she's\", 'her', 'hers', 'herself',\n",
      "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
      "                ('svc', SVC())])\n"
     ]
    }
   ],
   "source": [
    "# find the best estimators for both models\n",
    "\n",
    "print(f'Multinomial Naive Bayes: \\n{gs_mb.best_estimator_}')\n",
    "print(f'\\nSVC: \\n{gs_svc.best_estimator_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for Naive Bayes\n",
    "\n",
    "y_preds = gs_mb.predict(X_test)\n",
    "\n",
    "# confusion matrix values\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9177272727272727\n",
      "Specificity: 0.936480686695279\n",
      "Sensitivity: 0.8966183574879227\n",
      "Precision 0.9261477045908184\n"
     ]
    }
   ],
   "source": [
    "spec = tn / (tn + fp)\n",
    "sens = tp /(tp + fn)\n",
    "acc = (tp + tn)/(tn + fp + fn + tp)\n",
    "prec = tp / (tp + fp)\n",
    "\n",
    "print('Accuracy:', acc)\n",
    "print('Specificity:', spec)\n",
    "print('Sensitivity:', sens)\n",
    "print('Precision', prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for svc\n",
    "\n",
    "y_preds = gs_svc.predict(X_test)\n",
    "\n",
    "# confusion matrix values\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view confusion matrix\n",
    "\n",
    "plot_confusion_matrix(gs_svc, X_test, y_test, cmap = 'Blues', normalize = 'true');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
